{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7D-ClLnDbFpR","outputId":"7213fa15-0d3d-4c85-ca68-32644e0dfa85","executionInfo":{"status":"ok","timestamp":1678200626737,"user_tz":300,"elapsed":13747,"user":{"displayName":"Tuan Tran","userId":"03196305730134920723"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"drive/My Drive/github/HEprediction\")\n","!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n","import monai\n","from monai.data import  DataLoader, ImageDataset\n","from monai.transforms import (\n","    Resize, NormalizeIntensity, Activations, Compose, EnsureType, CenterSpatialCrop,ScaleIntensity,ResizeWithPadOrCrop, ResizeWithPadOrCropd,\n","    LoadImaged, EnsureChannelFirstd, EnsureTyped, NormalizeIntensityd, ScaleIntensityd,AddChannel\n",")\n","from monai.data import CacheDataset, DataLoader, ImageDataset, Dataset\n","from monai.data import decollate_batch\n","from monai.networks.nets import DenseNet121\n","from skimage.morphology import disk, binary_dilation, binary_erosion, remove_small_objects\n","import pandas as pd\n","import numpy as np\n","import nibabel as nib\n","import torch\n","import scipy.ndimage as nd\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import nibabel.processing\n","from monai.utils import set_determinism\n","from MyDenseNet import MyDenseNet121\n","import random\n","import scipy\n","random.seed(123)\n","set_determinism(seed=123)\n","from monai.metrics import DiceMetric\n","from monai.networks.nets import SegResNet\n","from monai.inferers import sliding_window_inference\n","from sklearn.metrics import (\n","    classification_report, confusion_matrix,\n","    ConfusionMatrixDisplay\n",")\n","VAL_AMP = True\n","def inference(input):\n","    def _compute(input):\n","        return sliding_window_inference(\n","            inputs=input,\n","            roi_size=(256, 256, 32),\n","            sw_batch_size=4,\n","            predictor=model,\n","            overlap=0.5,\n","        )\n","\n","    if VAL_AMP:\n","        with torch.cuda.amp.autocast():\n","            return _compute(input)\n","    else:\n","        return _compute(input)\n","from monai.transforms import (\n","    Activations, AsDiscrete,\n","    Compose\n",")\n","import warnings\n","warnings.filterwarnings('ignore')\n","import time\n","import os.path\n","from os import path\n","X=0\n","Y=1\n","Z=2\n","def enable_dropout(model):\n","    for module in model.modules():\n","        if 'Dropout' in type(module).__name__:\n","            module.train()\n","def sigmoid(x):\n","    return np.exp(-np.logaddexp(0, -x))\n","import sys\n","def predictive_entropy(predictions):\n","    epsilon = sys.float_info.min\n","    predictive_entropy = -np.sum( np.mean(predictions, axis=0) * np.log(np.mean(predictions, axis=0) + epsilon),\n","            axis=-1)\n","    return predictive_entropy\n","\n","def resample3d(image, spacing, new_spacing):\n","    resize_x = spacing[X] / new_spacing[X]\n","    new_shape_x = np.round(image.shape[X] * resize_x)\n","    resize_x = float(new_shape_x) / float(image.shape[X])\n","    sx = spacing[X] / resize_x\n","\n","    resize_y = spacing[Y] / new_spacing[Y]\n","    new_shape_y = np.round(image.shape[Y] * resize_y)\n","    resize_y = new_shape_y / image.shape[Y]\n","    sy = spacing[Y] / resize_y\n","\n","    resize_z = spacing[Z] / new_spacing[Z]\n","    new_shape_z = np.round(image.shape[Z] * resize_z)\n","    resize_z = float(new_shape_z) / float(image.shape[Z])\n","    sz = spacing[Z] / resize_z\n","\n","    image = scipy.ndimage.interpolation.zoom(image, (resize_x, resize_y, resize_z), order=1)\n","\n","    return image\n","\n","\n","def getbrainwindow(nii):\n","    window_center, window_width = 40, 80\n","    tmpimg1 = nii.get_fdata()\n","    tmpimg1[tmpimg1 < 0] = 0\n","    tmpimg1[tmpimg1 > 200] = 0\n","    img_min = window_center - window_width // 2\n","    img_max = window_center + window_width // 2\n","    tmpimg1[tmpimg1 < img_min] = img_min\n","    tmpimg1[tmpimg1 > img_max] = img_max\n","    tmpimg1 = (tmpimg1 - tmpimg1.min()) / np.ptp(tmpimg1)\n","    return tmpimg1\n","\n","\n","def removeSkull(img1):\n","    img_bw = img1.copy()\n","    img_bw[img_bw > 0] = 1\n","    for slice in range(0, img_bw.shape[2]):\n","        if slice <= round(img_bw.shape[2] / 20) or slice > (img_bw.shape[2] - round(img_bw.shape[2] / 20)):\n","            img_bw[:, :, slice] = 0\n","        if img_bw[:, :, slice].sum() > 0:\n","            img_bw[:, :, slice] = binary_erosion(img_bw[:, :, slice].astype(np.uint8),\n","                                                 disk(4, dtype=bool))\n","            img_bw[:, :, slice] = remove_small_objects(img_bw[:, :, slice].astype(bool), 5000)\n","            img_bw[:, :, slice] = binary_dilation(img_bw[:, :, slice].astype(np.uint8),\n","                                                  disk(4, dtype=bool))\n","            img_bw[:, :, slice] = nd.binary_fill_holes(img_bw[:, :, slice].astype(np.uint8))\n","        if img_bw[:, :, slice].sum() > 0:\n","            mask = np.zeros(img_bw[:, :, slice].shape, dtype=np.uint8)\n","            contours = cv2.findContours(img_bw[:, :, slice].astype(np.uint8), cv2.RETR_TREE,\n","                                        cv2.CHAIN_APPROX_SIMPLE)\n","            contours = contours[0] if len(contours) == 2 else contours[1]\n","            big_contour = max(contours, key=cv2.contourArea)\n","            cv2.drawContours(mask, [big_contour], -1, (255, 255, 255), -1)\n","            img_bw[:, :, slice][mask == 0] = 0\n","            mask = np.zeros(img_bw[:, :, slice].shape, dtype=np.uint8)\n","            cv2.drawContours(mask, [big_contour], -1, (255, 255, 255), 10)\n","            img_bw[:, :, slice][mask == 255] = 0\n","    img1[img_bw == 0] = 0\n","    img1 = 1.0 * (img1 - img1.min()) / np.ptp(img1)\n","    return img1\n","\n","\n","def selectGroupSlice(tmpimg1, tmpimg1seg):\n","    # find the first slice which contains hematoma\n","    for slice1 in range(tmpimg1seg.shape[2]):\n","        if tmpimg1seg[:, :, slice1].sum() > 0:\n","            break\n","    # find the last slice which contains hematoma\n","    for slice2 in range(tmpimg1seg.shape[2] - 1, 0, -1):\n","        if tmpimg1seg[:, :, slice2].sum() > 0:\n","            break\n","    if slice1 < slice2:\n","        slice1 = slice1 - 16\n","        if slice1 < 0:\n","            slice1 = 0\n","        slice2 = slice2 + 16\n","        if slice2 > tmpimg1seg.shape[2] - 1:\n","            slice2 = tmpimg1seg.shape[2] - 1\n","        if slice2 - slice1 >= 96:\n","            slice2 = slice1 + 96\n","        img1 = np.zeros([tmpimg1.shape[0], tmpimg1.shape[1], 96])\n","        img1seg = np.zeros([tmpimg1seg.shape[0], tmpimg1seg.shape[1], 96])\n","        img1[:, :, 0:slice2 - slice1] = tmpimg1[:, :, slice1:slice2]\n","        img1seg[:, :, 0:slice2 - slice1] = tmpimg1seg[:, :, slice1:slice2]\n","    else:\n","        img1 = np.zeros([tmpimg1.shape[0], tmpimg1.shape[1], 96])\n","        img1[:, :, 0:64] = tmpimg1[:, :,\n","                           int(np.round(tmpimg1.shape[2] / 2) - 32):int(np.round(tmpimg1.shape[2] / 2) + 32)]\n","        img1seg = np.zeros([tmpimg1seg.shape[0], tmpimg1seg.shape[1], 96])\n","    img1 = 1.0 * (img1 - img1.min()) / np.ptp(img1)\n","    return img1, img1seg\n","\n","\n","def getDilation(img1, img1seg):\n","    if img1seg.sum() <= 0:\n","        return img1seg\n","    img1dilation = img1.copy()\n","    img_bw = img1seg.copy()\n","    for slice in range(0, img_bw.shape[2]):\n","        if img_bw[:, :, slice].sum() > 0:\n","            img_bw[:, :, slice] = binary_dilation(img_bw[:, :, slice].astype(np.uint8),\n","                                                  disk(40, dtype=bool))\n","    img1dilation[img_bw == 0] = 0\n","    img1dilation = 1.0 * (img1dilation - img1dilation.min()) / np.ptp(img1dilation)\n","    return img1dilation\n","\n","\n","def resizeImg(img1, size):\n","    resizeImage = ResizeWithPadOrCrop(spatial_size=size)\n","    image = np.zeros([1, img1.shape[0], img1.shape[1], img1.shape[2]])\n","    image[0, :, :, :] = img1\n","    image = resizeImage(image)\n","    return image\n"]},{"cell_type":"code","source":["# Preprocessing for segmentation\n","# Input: CT files in italy_ds/baseline, mask in italy_ds/mask\n","# Output: brain window _brain.nii.gz and groundtruth _ich_seg.nii.gz with size (512x512x48) in folder italy_ds/preprocessing\n","# Code extract brain window, skull stripping and remove small objects, boundary. ResizeWithPadOrCrop to (512x512x48)\n","total_start = time.time()\n","data_dir = \"italy_ds/\"\n","output_path = data_dir + \"preprocessing\"\n","raw_data = pd.read_csv(os.path.join(data_dir, \"labels.csv\"), sep=\";\")\n","for _, c_row in raw_data.iterrows():\n","    patient = str(c_row['filename'])\n","    if path.exists(os.path.join(output_path, patient + \"_brain.nii.gz\")) == True:\n","        continue\n","    print(\"Processing: \", patient)\n","    pathCT1 = os.path.join(data_dir, \"baseline\", patient + \"_head.nii.gz\")\n","    nii = nib.load(pathCT1)\n","    img1 = getbrainwindow(nii)\n","    spacing = nii.header['pixdim'][1:4]\n","    if img1.shape[2] > 48:\n","        new_spacing = [spacing[0], spacing[1], 5]\n","        img1 = resample3d(img1, spacing, new_spacing)\n","    else:\n","        new_spacing = spacing\n","    img1 = removeSkull(img1)\n","    image = resizeImg(img1, (512, 512, 48))\n","    empty_header = nib.Nifti1Header()\n","    affine = np.eye(4)\n","    affine[:3, :3] = np.diag(new_spacing)\n","    clipped_img = nib.Nifti1Image(image[0, :, :, :], affine, empty_header)\n","    nib.save(clipped_img, os.path.join(output_path, patient + \"_brain.nii.gz\"))\n","total_time = time.time() - total_start\n","print(\"Finish: \", total_time)"],"metadata":{"id":"a7h-dJWUS6Ah","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd090738-603e-43a1-9d98-6cc6609d8e50","executionInfo":{"status":"ok","timestamp":1678200649085,"user_tz":300,"elapsed":5348,"user":{"displayName":"Tuan Tran","userId":"03196305730134920723"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Finish:  5.089249849319458\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"oVJ9_n8OZSlq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f109ab09-3572-4d34-b21a-bf9bf40c2f70","executionInfo":{"status":"ok","timestamp":1678200995081,"user_tz":300,"elapsed":331663,"user":{"displayName":"Tuan Tran","userId":"03196305730134920723"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Finish:  332.01940298080444\n"]}],"source":["#Segmentation\n","#Input: brain window _brain.nii.gz and groundtruth _ich_seg.nii.gz with size (512x512x48) in folder italy_ds/preprocessing\n","#Output: hematoma region in folder italy_ds/preprocessing/*_seg_auto.nii.gz with size (512x512x48)\n","#Using SegResNet model\n","total_start = time.time()\n","data_dir = \"italy_ds/\"\n","output_path=data_dir + \"preprocessing\"\n","raw_data = pd.read_csv(os.path.join(data_dir, \"labels.csv\"), sep=\";\")\n","xtest = []\n","nametest = []\n","for _, c_row in raw_data.iterrows():\n","    xtest = np.append(xtest, os.path.join(output_path, str(c_row['filename']) + \"_brain.nii.gz\"))\n","    nametest = np.append(nametest, str(c_row['filename']))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","test_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"image\"]),\n","        EnsureChannelFirstd(keys=[\"image\"]),\n","        EnsureTyped(keys=[\"image\"]),\n","        NormalizeIntensityd(keys=\"image\"),\n","        ScaleIntensityd(keys=\"image\"),\n","    ]\n",")\n","num_batch = 1\n","test_files = [{\"image\": t2Img, \"name\": name} for t2Img, name in\n","              zip(xtest, nametest)]\n","test_ds = Dataset(data=test_files, transform=test_transforms)\n","test_loader = DataLoader(test_ds, batch_size=num_batch, shuffle=False,\n","                         num_workers=num_batch, pin_memory=torch.cuda.is_available())\n","model = SegResNet(\n","    blocks_down=[1, 2, 2, 4],\n","    blocks_up=[1, 1, 1],\n","    init_filters=16,\n","    in_channels=1,\n","    out_channels=1,\n","    dropout_prob=0.2,\n",").to(device)\n","model.load_state_dict(\n","    torch.load(os.path.join(\"full_6000_new_best_metric_model_segmentation3d_1_1.pth\")))\n","\n","post_trans = Compose(\n","    [Activations(sigmoid=True), AsDiscrete(threshold=0.5)]\n",")\n","\n","model.eval()\n","with torch.no_grad():\n","    num = 0\n","    for val_data in test_loader:\n","        if path.exists(os.path.join(output_path, str(val_data[\"name\"][0]) + \"_seg_auto.nii.gz\"))==True:\n","              continue\n","        val_inputs = val_data[\"image\"].to(device)\n","        val_outputs = inference(val_inputs)\n","        val_outputs = post_trans(val_outputs)\n","        for p in range(num_batch):\n","            print(num, \". Patient:\", val_data[\"name\"][p])\n","            num = num + 1\n","            t1 = val_outputs[p, 0, :, :, :].cpu().numpy()\n","            nii = nib.load(os.path.join(output_path, str(val_data[\"name\"][p]) + \"_brain.nii.gz\"))\n","            empty_header = nib.Nifti1Header()\n","            affine = np.eye(4)\n","            affine[:3, :3] = np.diag((nii.header[\"pixdim\"])[1:4])\n","            pathCT1seg = os.path.join(output_path, str(val_data[\"name\"][p]) + \"_seg_auto.nii.gz\")\n","            imgseg = nib.Nifti1Image(t1, affine, empty_header)\n","            nib.save(imgseg, pathCT1seg)\n","total_time = time.time() - total_start\n","print(\"Finish: \", total_time)"]},{"cell_type":"code","source":["# Preprocessing for classification\n","# Input: CT files in italy_ds/baseline, hematoma region in italy_ds/preprocessing/*_seg_auto.nii.gz\n","# Output: brain windows and hematoma region in folder italy_ds/classification/*_brain_seg_dilation.nii.gz with size (2x128x128x96)\n","# Code: Get brain window from preprocessing of segmentation step, resample. Select group of slices containing Hematoma\n","# Resize to 2x192x192x96\n","# CenterSpatialCrop to 2x128x128x96\n","total_start = time.time()\n","data_dir = \"italy_ds/\"\n","output_path = data_dir + \"preprocessing\"\n","raw_data = pd.read_csv(os.path.join(data_dir, \"labels.csv\"), sep=\";\")\n","xtest = []\n","ytest = []\n","nametest = []\n","for _, c_row in raw_data.iterrows():\n","    patient = str(c_row['filename'])\n","    if path.exists(os.path.join(data_dir, \"classification\", patient + \"_brain_seg_dilation.nii.gz\")) == True:\n","        continue\n","    print(\"Patient:\" + patient)\n","    pathCT1seg = os.path.join(output_path, str(c_row['filename']) + \"_seg_auto.nii.gz\")\n","    nii = nib.load(pathCT1seg)\n","    spacing = (nii.header[\"pixdim\"])[1:4]\n","    voxel_size = [1, 1, 1]\n","    tmpimg1seg = nii.get_fdata()\n","    for i in range(tmpimg1seg.shape[2]):\n","        if np.sum(tmpimg1seg[:, :, i]) < 50:\n","            tmpimg1seg[:, :, i] = 0\n","    tmpimg1seg = resample3d(tmpimg1seg, spacing, voxel_size)\n","    tmpimg1seg[tmpimg1seg > 0] = 1\n","\n","    pathCT1 = os.path.join(output_path, patient + \"_brain.nii.gz\")\n","    nii = nib.load(pathCT1)\n","    tmpimg1 = nii.get_fdata()\n","    tmpimg1 = resample3d(tmpimg1, spacing, voxel_size)\n","\n","    img1, img1seg = selectGroupSlice(tmpimg1, tmpimg1seg)\n","    img1dilation = getDilation(img1, img1seg)\n","\n","    image = np.zeros([2, img1.shape[0], img1.shape[1], img1.shape[2]])\n","    image[0, :, :, :] = img1\n","    image[1, :, :, :] = img1dilation\n","    resizeImage = Resize([192, 192, 96])\n","    cropImage = CenterSpatialCrop(roi_size=(128, 128, 96))\n","    scaleImage = ScaleIntensity()\n","    image = resizeImage(image)\n","    image = cropImage(image)\n","    image = scaleImage(image)\n","    # save file\n","    pathCT1clipseg = os.path.join(data_dir, \"classification\", patient + \"_brain_seg_dilation.nii.gz\")\n","    empty_header = nib.Nifti1Header()\n","    nii = nib.load(pathCT1)\n","    clipped_img = nib.Nifti1Image(image, nii.affine, empty_header)\n","    nib.save(clipped_img, pathCT1clipseg)\n","total_time = time.time() - total_start\n","print(\"Finish: \", total_time)\n"],"metadata":{"id":"RAy9P3MnykwL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"35029e02-6a35-4c0e-fbea-43b596cfe106","executionInfo":{"status":"ok","timestamp":1678201002252,"user_tz":300,"elapsed":293,"user":{"displayName":"Tuan Tran","userId":"03196305730134920723"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Finish:  0.024365663528442383\n"]}]},{"cell_type":"code","source":["# Classification\n","# Input: brain windows and hematoma region in folder italy_ds/classification/*_brain_seg_dilation.nii.gz (2x128x128x96)\n","# Output: AUC\n","# Code: using MyDenseNet121 which is developed from DenseNet121\n","total_start = time.time()\n","root_dir = \"italy_ds/\"\n","data_dir = os.path.join(root_dir, \"classification\")\n","raw_data = pd.read_csv(os.path.join(root_dir, \"labels.csv\"), sep=\";\")\n","pathFilenames = []\n","labels = []\n","names = []\n","for _, c_row in raw_data.iterrows():\n","    pathFilenames.append(os.path.join(data_dir, str(c_row['filename']) + \"_brain_seg_dilation.nii.gz\"))\n","    labels.append(c_row['label'])\n","    names.append(str(c_row['filename']))\n","labels = np.asarray(labels).astype(int)\n","pathFilenames = np.asarray(pathFilenames)\n","names = np.asarray(names)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MyDenseNet121(spatial_dims=3, in_channels=2, out_channels=128, dropout_prob=0.1).to(device)\n","model.load_state_dict(torch.load(\"6000x5auc_classification3d_110.pth\"))\n","model.eval()\n","xval = pathFilenames\n","yval = labels\n","val_ds = ImageDataset(\n","    image_files=xval, labels=yval)\n","val_loader = DataLoader(val_ds, batch_size=10, shuffle=False,\n","                        num_workers=10, pin_memory=torch.cuda.is_available())\n","y_pred_trans = Compose([EnsureType(), Activations(sigmoid=True)])\n","y_trans = Compose([EnsureType()])\n","with torch.no_grad():\n","    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n","    y = torch.tensor([], dtype=torch.double, device=device)\n","    for val_data in val_loader:\n","        inputs, val_labels = val_data[0].to(\n","            device), val_data[1].to(device)\n","        val_outputs = model(inputs)\n","        y_pred1 = val_outputs.flatten()\n","        y1 = val_labels\n","        y_pred = torch.cat([y_pred, y_pred1], dim=0)\n","        y = torch.cat([y, y1], dim=0)\n","    y_onehot = [y_trans(i) for i in decollate_batch(y)]\n","    y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n","    auc_metric1 = monai.metrics.ROCAUCMetric()\n","    auc_metric1(y_pred_act, y_onehot)\n","    print(\"AUC total= \", auc_metric1.aggregate())\n","    auc_metric1.reset()\n","total_time = time.time() - total_start\n","print(\"Finish: \", total_time)\n"],"metadata":{"id":"4Up055RkynrM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"006fd59b-a144-4957-f20e-3daa9557e81a","executionInfo":{"status":"ok","timestamp":1678201019923,"user_tz":300,"elapsed":13618,"user":{"displayName":"Tuan Tran","userId":"03196305730134920723"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["AUC total=  0.8208041958041958\n","Finish:  13.065118312835693\n"]}]},{"cell_type":"code","source":["# Classification using MC\n","# Input: brain windows and hematoma region in folder italy_ds/classification/*_brain_seg_dilation.nii.gz (2x128x128x96)\n","# Output: AUC\n","# Code: using MyDenseNet121 which is developed from DenseNet121\n","total_start = time.time()\n","root_dir = \"italy_ds/\"\n","data_dir = os.path.join(root_dir, \"classification\")\n","raw_data = pd.read_csv(os.path.join(root_dir, \"labels.csv\"), sep=\";\")\n","pathFilenames = []\n","labels = []\n","names = []\n","for _, c_row in raw_data.iterrows():\n","    pathFilenames.append(os.path.join(data_dir, str(c_row['filename']) + \"_brain_seg_dilation.nii.gz\"))\n","    labels.append(c_row['label'])\n","    names.append(str(c_row['filename']))\n","labels = np.asarray(labels).astype(int)\n","pathFilenames = np.asarray(pathFilenames)\n","names = np.asarray(names)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MyDenseNet121(spatial_dims=3, in_channels=2, out_channels=128, dropout_prob=0.1).to(device)\n","model.load_state_dict(torch.load(\"6000x5auc_classification3d_110.pth\"))\n","model.eval()\n","enable_dropout(model)\n","xval = pathFilenames\n","yval = labels\n","val_ds = ImageDataset(\n","    image_files=xval, labels=yval)\n","val_loader = DataLoader(val_ds, batch_size=10, shuffle=False,\n","                        num_workers=10, pin_memory=torch.cuda.is_available())\n","y_pred_trans = Compose([EnsureType(), Activations(sigmoid=True)])\n","y_trans = Compose([EnsureType()])\n","with torch.no_grad():\n","    dropout_predictions = np.empty((0, yval.shape[0]))\n","    y = torch.tensor([], dtype=torch.double, device=device)\n","    for step in range(10):\n","        y_pred = torch.tensor([], dtype=torch.float32, device=device)\n","        for val_data in val_loader:\n","            inputs, val_labels = val_data[0].to(\n","                device), val_data[1].to(device)\n","            val_outputs = model(inputs)\n","            y_pred1 = val_outputs.flatten()\n","            y1 = val_labels\n","            y_pred = torch.cat([y_pred, y_pred1], dim=0)\n","            if step == 0:\n","                y = torch.cat([y, y1], dim=0)\n","        dropout_predictions = np.vstack((dropout_predictions,\n","                                         y_pred[np.newaxis, :]))\n","    mean = np.mean((dropout_predictions), axis=0)\n","    y_onehot = [y_trans(i) for i in decollate_batch(y)]\n","    y_pred_act = [y_pred_trans(i) for i in decollate_batch((mean))]\n","    auc_metric1 = monai.metrics.ROCAUCMetric()\n","    auc_metric1(y_pred_act, y_onehot)\n","    print(\"AUC total= \")\n","    print(auc_metric1.aggregate())\n","    auc_metric1.reset()\n","print(\"Finish\")\n","total_time = time.time() - total_start\n","print(total_time)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yxSAK7oWDfPc","executionInfo":{"status":"ok","timestamp":1678202412800,"user_tz":300,"elapsed":106060,"user":{"displayName":"Tuan Tran","userId":"03196305730134920723"}},"outputId":"83de52da-101f-4ca8-80c3-2d131d4d5840"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["AUC total= \n","0.8050699300699301\n","Finish\n","105.83462858200073\n"]}]},{"cell_type":"code","source":["# Classification using MC\n","# Input: brain windows and hematoma region in folder italy_ds/classification/*_brain_seg_dilation.nii.gz (2x128x128x96)\n","# Output: AUC\n","# Code: using MyDenseNet121 which is developed from DenseNet121\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","expectAUC = 0.82\n","variance = np.var(dropout_predictions, axis=0)  # shape (n_samples, n_classes)\n","std = np.std(dropout_predictions, axis=0)  # shape (n_samples, n_classes)\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","J_stats = [None]\n","opt_thresholds = [None]\n","thresholds = dict()\n","y1 = y.cpu().numpy().copy()\n","name1 = names.copy()\n","mean1 = mean.copy()\n","entropy=[]\n","for k in range(yval.shape[0]):    \n","    tmp = predictive_entropy(sigmoid(dropout_predictions[:,k]))\n","    entropy = np.append(entropy, tmp)\n","auc=[]\n","auc=[]\n","sort_values = sorted(zip(entropy, y1, mean1, name1), key=lambda x:x[0], reverse=True)\n","entropy, y1, mean1, name1 = zip(*sort_values)\n","for i in range(len(entropy)-1):    \n","    y1 = np.delete(y1, 0)\n","    mean1 = np.delete(mean1, 0)\n","    y_onehot = [y_trans(i) for i in decollate_batch(y1)]\n","    y_pred_act = [y_pred_trans(i) for i in decollate_batch((mean1))]\n","    auc_metric1 = monai.metrics.ROCAUCMetric()\n","    auc_metric1(y_pred_act, y_onehot)\n","    auc = np.append(auc, auc_metric1.aggregate())\n","    auc_metric1.reset()\n","auc = np.append(auc, 1)\n","plt.plot(entropy, auc, color='green')\n","plt.ylim(0, 1)\n","plt.xlim(np.max(entropy),np.min(entropy))\n","plt.xlabel('entropy')\n","plt.ylabel('AUC')\n","plt.title('AUC using entropy')\n","plt.show()\n","indexAUC = np.where(auc>expectAUC)[0][0]\n","threshold = entropy[indexAUC]\n","y1 = y.cpu().numpy().copy()\n","mean1 = mean.copy()\n","std1 = std.copy()\n","entropy=[]\n","for k in range(yval.shape[0]):    \n","    tmp = predictive_entropy(sigmoid(dropout_predictions[:,k]))\n","    entropy = np.append(entropy, tmp)\n","index = np.where(entropy>=threshold)[0]\n","print(\"Uncertainty: \", end =\" \")\n","for k in range(len(index)):\n","  print(name1[k], \",\" , end =\" \")\n","y1 = np.delete(y1, index)\n","mean1 = np.delete(mean1,index)\n","name1 = np.delete(name1, index)\n","print(\"\\nHigh confident: \", end =\" \")\n","print(list(name1))\n","y_onehot = [y_trans(i) for i in decollate_batch(y1)]\n","y_pred_act = [y_pred_trans(i) for i in decollate_batch((mean1))]\n","auc_metric1 = monai.metrics.ROCAUCMetric()\n","auc_metric1(y_pred_act, y_onehot)\n","print(\"AUC total= \")\n","print(auc_metric1.aggregate())\n","auc_metric1.reset()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"21YtPhm78Kf1","executionInfo":{"status":"ok","timestamp":1678202422382,"user_tz":300,"elapsed":2989,"user":{"displayName":"Tuan Tran","userId":"03196305730134920723"}},"outputId":"7517a269-e8eb-4f4e-8065-8dcc52d7c5f6"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["Uncertainty:  093_E108074625 , 101_E108257268 , 179_E110063911 , 197_E104404205 , 170_E109873730 , 108_E108431861 , 163_E109687083 , 080_E107724418 , 241_E111656351 , 159_E109595731 , 105_E108340479 , 084_E107845421 , 074_E107567072 , 026_E106416453 , 239_E111571087 , 118_E108723029 , 161_E109629626 , 047_E106880231 , 127_E108872750 , 008_E101982858 , 154_E109530516 , \n","High confident:  ['093_E108074625', '179_E110063911', '197_E104404205', '170_E109873730', '108_E108431861', '163_E109687083', '080_E107724418', '159_E109595731', '105_E108340479', '084_E107845421', '026_E106416453', '239_E111571087', '118_E108723029', '161_E109629626', '047_E106880231', '127_E108872750', '008_E101982858', '169_E109839821', '064_E107148589', '061_E107182509', '142_E109248030', '261_E105884483', '124_E103464034', '165_E109694498', '235_E111504016', '171_E109880093', '131_E108980070', '146_E109315591', '200_E110559584', '021_E106360734', '167_E109747437', '073_E107560178', '032_E102498045', '136_E109081638', '007_E101864697', '088_E107932321', '090_E108007331', '046_E102606756', '229_E111355511', '224_E104903227', '205_E110676285', '153_E109514800', '092_E108068654', '173_E109931893', '063_E107234783', '158_E109593054', '104_E103241978', '194_E110262079', '168_E109842621', '013_E102136485', '162_E109650311', '015_E102280535', '125_E108849527', '140_E109162409', '231_E111390758', '129_E108891550', '193_E110248178', '137_E109093208', '245_E105356171', '186_E110161815', '025_E106396366', '196_E110306327', '177_E110037853', '126_E103494684', '277_E106275326', '233_E111397179', '271_E106206336', '246_E105401766', '160_E109615002', '018_E102420270', '072_E107542911', '135_E103578786', '069_E107347102', '215_E110852512', '113_E108570872', '172_E109946022', '257_E105755828', '045_E102579315', '065_E102867714', '155_E109528575']\n","AUC total= \n","0.8211805555555556\n"]}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}